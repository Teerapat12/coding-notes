{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee0c611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor \n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPUs\")\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bfb3e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "{'train': 50000, 'test': 5000, 'validation': 5000}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "batch_size = 32\n",
    "# mean, std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize(mean, std),\n",
    "    torchvision.transforms.RandomCrop(32, padding=4, padding_mode='constant'),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "train_size = len(train_set)\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_set, validation_set = torch.utils.data.random_split(test_set, [5000, 5000])\n",
    "test_size = len(test_set)\n",
    "validation_size = len(validation_set)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size, num_workers=4, pin_memory=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"test\": test_loader, \"validation\": validation_loader}\n",
    "dataset_sizes = {\"train\": train_size, \"test\": test_size, \"validation\": validation_size}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6197cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, down=False):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, stride=stride, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.downsample = None\n",
    "        \n",
    "        if down:\n",
    "            self.downsample = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride)\n",
    "        \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model_n, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_layers = nn.ModuleList([])\n",
    "        self.model_n = model_n\n",
    "\n",
    "        ### begining layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        ######## ResNet blocks [16, 32, 64]\n",
    "        ### first block, 16 channels\n",
    "        for i in range(self.model_n):\n",
    "            self.residual_layers.append(BasicBlock(16, 16).to(device))\n",
    "            \n",
    "        \n",
    "        ### second block, 32 channels\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(BasicBlock(16, 32, stride=2, down=True).to(device))\n",
    "            else:\n",
    "                self.residual_layers.append(BasicBlock(32, 32).to(device))\n",
    "                \n",
    "                \n",
    "        ### third block, 64 channels\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(BasicBlock(32, 64, stride=2, down=True).to(device))\n",
    "                self.inplanes = 64\n",
    "            else:\n",
    "                self.residual_layers.append(BasicBlock(64, 64).to(device))\n",
    "        \n",
    "    \n",
    "        ### output layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "\n",
    "        ### begining layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        ##### ResNet blocks\n",
    "        for i, layer in enumerate(self.residual_layers):\n",
    "            x = layer (x)\n",
    "            \n",
    "            \n",
    "        ### output layers\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = ResNet(model_n=3)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80], gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "953823b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "------------------------------\n",
      "{'time': 27.23867, 'train_loss': 0.90516, 'train_acc': 0.6806, 'val_loss': 0.83081, 'val_acc': 0.7124}\n",
      "Epoch 1/99\n",
      "------------------------------\n",
      "{'time': 29.44841, 'train_loss': 0.76974, 'train_acc': 0.73092, 'val_loss': 0.72863, 'val_acc': 0.7468}\n",
      "Epoch 2/99\n",
      "------------------------------\n",
      "{'time': 28.2496, 'train_loss': 0.68516, 'train_acc': 0.7627, 'val_loss': 0.69881, 'val_acc': 0.7534}\n",
      "Epoch 3/99\n",
      "------------------------------\n",
      "{'time': 32.9939, 'train_loss': 0.6268, 'train_acc': 0.78626, 'val_loss': 0.65467, 'val_acc': 0.7718}\n",
      "Epoch 4/99\n",
      "------------------------------\n",
      "{'time': 31.12182, 'train_loss': 0.58508, 'train_acc': 0.79632, 'val_loss': 0.58427, 'val_acc': 0.796}\n",
      "Epoch 5/99\n",
      "------------------------------\n",
      "{'time': 30.68745, 'train_loss': 0.54633, 'train_acc': 0.80996, 'val_loss': 0.58102, 'val_acc': 0.7996}\n",
      "Epoch 6/99\n",
      "------------------------------\n",
      "{'time': 29.11135, 'train_loss': 0.523, 'train_acc': 0.82008, 'val_loss': 0.5447, 'val_acc': 0.8134}\n",
      "Epoch 7/99\n",
      "------------------------------\n",
      "{'time': 28.67365, 'train_loss': 0.49257, 'train_acc': 0.83068, 'val_loss': 0.58336, 'val_acc': 0.7974}\n",
      "Epoch 8/99\n",
      "------------------------------\n",
      "{'time': 30.34379, 'train_loss': 0.46865, 'train_acc': 0.8387, 'val_loss': 0.50733, 'val_acc': 0.8206}\n",
      "Epoch 9/99\n",
      "------------------------------\n",
      "{'time': 30.43416, 'train_loss': 0.45208, 'train_acc': 0.84446, 'val_loss': 0.52935, 'val_acc': 0.8166}\n",
      "Epoch 10/99\n",
      "------------------------------\n",
      "{'time': 30.97527, 'train_loss': 0.4347, 'train_acc': 0.8503, 'val_loss': 0.50061, 'val_acc': 0.8254}\n",
      "Epoch 11/99\n",
      "------------------------------\n",
      "{'time': 31.37665, 'train_loss': 0.42259, 'train_acc': 0.85352, 'val_loss': 0.51601, 'val_acc': 0.8252}\n",
      "Epoch 12/99\n",
      "------------------------------\n",
      "{'time': 29.93124, 'train_loss': 0.40227, 'train_acc': 0.86136, 'val_loss': 0.4686, 'val_acc': 0.8392}\n",
      "Epoch 13/99\n",
      "------------------------------\n",
      "{'time': 33.37626, 'train_loss': 0.39044, 'train_acc': 0.86488, 'val_loss': 0.45129, 'val_acc': 0.8496}\n",
      "Epoch 14/99\n",
      "------------------------------\n",
      "{'time': 29.04011, 'train_loss': 0.3767, 'train_acc': 0.87022, 'val_loss': 0.52241, 'val_acc': 0.8284}\n",
      "Epoch 15/99\n",
      "------------------------------\n",
      "{'time': 28.34489, 'train_loss': 0.36364, 'train_acc': 0.8739, 'val_loss': 0.4263, 'val_acc': 0.853}\n",
      "Epoch 16/99\n",
      "------------------------------\n",
      "{'time': 28.65892, 'train_loss': 0.35378, 'train_acc': 0.87744, 'val_loss': 0.42579, 'val_acc': 0.8572}\n",
      "Epoch 17/99\n",
      "------------------------------\n",
      "{'time': 28.39786, 'train_loss': 0.34142, 'train_acc': 0.88102, 'val_loss': 0.44008, 'val_acc': 0.852}\n",
      "Epoch 18/99\n",
      "------------------------------\n",
      "{'time': 29.76353, 'train_loss': 0.33295, 'train_acc': 0.88404, 'val_loss': 0.42658, 'val_acc': 0.8518}\n",
      "Epoch 19/99\n",
      "------------------------------\n",
      "{'time': 29.63728, 'train_loss': 0.32852, 'train_acc': 0.8851, 'val_loss': 0.44049, 'val_acc': 0.8524}\n",
      "Epoch 20/99\n",
      "------------------------------\n",
      "{'time': 29.92877, 'train_loss': 0.31817, 'train_acc': 0.8887, 'val_loss': 0.42347, 'val_acc': 0.8532}\n",
      "Epoch 21/99\n",
      "------------------------------\n",
      "{'time': 29.60035, 'train_loss': 0.31363, 'train_acc': 0.89032, 'val_loss': 0.40397, 'val_acc': 0.8654}\n",
      "Epoch 22/99\n",
      "------------------------------\n",
      "{'time': 28.86688, 'train_loss': 0.30369, 'train_acc': 0.89276, 'val_loss': 0.42378, 'val_acc': 0.8602}\n",
      "Epoch 23/99\n",
      "------------------------------\n",
      "{'time': 28.6193, 'train_loss': 0.29423, 'train_acc': 0.89622, 'val_loss': 0.43406, 'val_acc': 0.8582}\n",
      "Epoch 24/99\n",
      "------------------------------\n",
      "{'time': 35.17987, 'train_loss': 0.29001, 'train_acc': 0.89808, 'val_loss': 0.39983, 'val_acc': 0.864}\n",
      "Epoch 25/99\n",
      "------------------------------\n",
      "{'time': 30.45633, 'train_loss': 0.28657, 'train_acc': 0.90082, 'val_loss': 0.41652, 'val_acc': 0.8582}\n",
      "Epoch 26/99\n",
      "------------------------------\n",
      "{'time': 30.4171, 'train_loss': 0.27787, 'train_acc': 0.9015, 'val_loss': 0.43677, 'val_acc': 0.8538}\n",
      "Epoch 27/99\n",
      "------------------------------\n",
      "{'time': 30.9833, 'train_loss': 0.27045, 'train_acc': 0.90514, 'val_loss': 0.42186, 'val_acc': 0.859}\n",
      "Epoch 28/99\n",
      "------------------------------\n",
      "{'time': 30.26642, 'train_loss': 0.26953, 'train_acc': 0.905, 'val_loss': 0.44103, 'val_acc': 0.8546}\n",
      "Epoch 29/99\n",
      "------------------------------\n",
      "{'time': 29.73605, 'train_loss': 0.26226, 'train_acc': 0.9072, 'val_loss': 0.41635, 'val_acc': 0.861}\n",
      "Epoch 30/99\n",
      "------------------------------\n",
      "{'time': 29.42417, 'train_loss': 0.25676, 'train_acc': 0.90948, 'val_loss': 0.43242, 'val_acc': 0.8618}\n",
      "Epoch 31/99\n",
      "------------------------------\n",
      "{'time': 29.12553, 'train_loss': 0.24964, 'train_acc': 0.91338, 'val_loss': 0.40791, 'val_acc': 0.8712}\n",
      "Epoch 32/99\n",
      "------------------------------\n",
      "{'time': 29.1493, 'train_loss': 0.24842, 'train_acc': 0.91312, 'val_loss': 0.40185, 'val_acc': 0.8688}\n",
      "Epoch 33/99\n",
      "------------------------------\n",
      "{'time': 32.22311, 'train_loss': 0.24077, 'train_acc': 0.91538, 'val_loss': 0.42547, 'val_acc': 0.866}\n",
      "Epoch 34/99\n",
      "------------------------------\n",
      "{'time': 29.29594, 'train_loss': 0.23663, 'train_acc': 0.918, 'val_loss': 0.38588, 'val_acc': 0.877}\n",
      "Epoch 35/99\n",
      "------------------------------\n",
      "{'time': 30.2259, 'train_loss': 0.23269, 'train_acc': 0.9186, 'val_loss': 0.4007, 'val_acc': 0.8688}\n",
      "Epoch 36/99\n",
      "------------------------------\n",
      "{'time': 30.06252, 'train_loss': 0.22692, 'train_acc': 0.9178, 'val_loss': 0.41722, 'val_acc': 0.8678}\n",
      "Epoch 37/99\n",
      "------------------------------\n",
      "{'time': 29.24465, 'train_loss': 0.22861, 'train_acc': 0.91946, 'val_loss': 0.38403, 'val_acc': 0.8748}\n",
      "Epoch 38/99\n",
      "------------------------------\n",
      "{'time': 29.8483, 'train_loss': 0.22126, 'train_acc': 0.92206, 'val_loss': 0.41477, 'val_acc': 0.8688}\n",
      "Epoch 39/99\n",
      "------------------------------\n",
      "{'time': 30.43328, 'train_loss': 0.21953, 'train_acc': 0.92256, 'val_loss': 0.43326, 'val_acc': 0.8678}\n",
      "Epoch 40/99\n",
      "------------------------------\n",
      "{'time': 26.98975, 'train_loss': 0.21104, 'train_acc': 0.92622, 'val_loss': 0.40278, 'val_acc': 0.8718}\n",
      "Epoch 41/99\n",
      "------------------------------\n",
      "{'time': 29.82189, 'train_loss': 0.2129, 'train_acc': 0.92442, 'val_loss': 0.39262, 'val_acc': 0.871}\n",
      "Epoch 42/99\n",
      "------------------------------\n",
      "{'time': 29.6554, 'train_loss': 0.20983, 'train_acc': 0.92638, 'val_loss': 0.3825, 'val_acc': 0.8754}\n",
      "Epoch 43/99\n",
      "------------------------------\n",
      "{'time': 28.74209, 'train_loss': 0.20441, 'train_acc': 0.92734, 'val_loss': 0.4163, 'val_acc': 0.8738}\n",
      "Epoch 44/99\n",
      "------------------------------\n",
      "{'time': 33.47371, 'train_loss': 0.20036, 'train_acc': 0.92822, 'val_loss': 0.3934, 'val_acc': 0.8736}\n",
      "Epoch 45/99\n",
      "------------------------------\n",
      "{'time': 30.76873, 'train_loss': 0.20141, 'train_acc': 0.929, 'val_loss': 0.36683, 'val_acc': 0.8802}\n",
      "Epoch 46/99\n",
      "------------------------------\n",
      "{'time': 30.43102, 'train_loss': 0.19419, 'train_acc': 0.93146, 'val_loss': 0.39416, 'val_acc': 0.877}\n",
      "Epoch 47/99\n",
      "------------------------------\n",
      "{'time': 31.24239, 'train_loss': 0.19191, 'train_acc': 0.9333, 'val_loss': 0.40801, 'val_acc': 0.8732}\n",
      "Epoch 48/99\n",
      "------------------------------\n",
      "{'time': 30.09348, 'train_loss': 0.19155, 'train_acc': 0.9316, 'val_loss': 0.39083, 'val_acc': 0.8758}\n",
      "Epoch 49/99\n",
      "------------------------------\n",
      "{'time': 30.66329, 'train_loss': 0.18401, 'train_acc': 0.93396, 'val_loss': 0.39382, 'val_acc': 0.8754}\n",
      "Epoch 50/99\n",
      "------------------------------\n",
      "{'time': 30.32473, 'train_loss': 0.18549, 'train_acc': 0.93386, 'val_loss': 0.38135, 'val_acc': 0.8792}\n",
      "Epoch 51/99\n",
      "------------------------------\n",
      "{'time': 33.58985, 'train_loss': 0.18167, 'train_acc': 0.93542, 'val_loss': 0.41453, 'val_acc': 0.875}\n",
      "Epoch 52/99\n",
      "------------------------------\n",
      "{'time': 29.07778, 'train_loss': 0.17732, 'train_acc': 0.93666, 'val_loss': 0.38732, 'val_acc': 0.8784}\n",
      "Epoch 53/99\n",
      "------------------------------\n",
      "{'time': 29.21154, 'train_loss': 0.17471, 'train_acc': 0.9384, 'val_loss': 0.3915, 'val_acc': 0.8836}\n",
      "Epoch 54/99\n",
      "------------------------------\n",
      "{'time': 29.38165, 'train_loss': 0.17179, 'train_acc': 0.93942, 'val_loss': 0.3911, 'val_acc': 0.8776}\n",
      "Epoch 55/99\n",
      "------------------------------\n",
      "{'time': 30.2452, 'train_loss': 0.17028, 'train_acc': 0.93924, 'val_loss': 0.40287, 'val_acc': 0.8772}\n",
      "Epoch 56/99\n",
      "------------------------------\n",
      "{'time': 28.97199, 'train_loss': 0.16805, 'train_acc': 0.93992, 'val_loss': 0.39558, 'val_acc': 0.8782}\n",
      "Epoch 57/99\n",
      "------------------------------\n",
      "{'time': 29.5497, 'train_loss': 0.16383, 'train_acc': 0.94148, 'val_loss': 0.40065, 'val_acc': 0.878}\n",
      "Epoch 58/99\n",
      "------------------------------\n",
      "{'time': 29.86961, 'train_loss': 0.16907, 'train_acc': 0.93948, 'val_loss': 0.39611, 'val_acc': 0.8842}\n",
      "Epoch 59/99\n",
      "------------------------------\n",
      "{'time': 29.26929, 'train_loss': 0.15589, 'train_acc': 0.94516, 'val_loss': 0.40674, 'val_acc': 0.879}\n",
      "Epoch 60/99\n",
      "------------------------------\n",
      "{'time': 29.56598, 'train_loss': 0.15885, 'train_acc': 0.94286, 'val_loss': 0.41499, 'val_acc': 0.8716}\n",
      "Epoch 61/99\n",
      "------------------------------\n",
      "{'time': 29.38278, 'train_loss': 0.15712, 'train_acc': 0.94484, 'val_loss': 0.41053, 'val_acc': 0.8726}\n",
      "Epoch 62/99\n",
      "------------------------------\n",
      "{'time': 34.37177, 'train_loss': 0.15731, 'train_acc': 0.944, 'val_loss': 0.41003, 'val_acc': 0.8746}\n",
      "Epoch 63/99\n",
      "------------------------------\n",
      "{'time': 31.12618, 'train_loss': 0.15334, 'train_acc': 0.94528, 'val_loss': 0.40483, 'val_acc': 0.8792}\n",
      "Epoch 64/99\n",
      "------------------------------\n",
      "{'time': 30.23949, 'train_loss': 0.14956, 'train_acc': 0.94742, 'val_loss': 0.39744, 'val_acc': 0.8786}\n",
      "Epoch 65/99\n",
      "------------------------------\n",
      "{'time': 30.32789, 'train_loss': 0.15347, 'train_acc': 0.94472, 'val_loss': 0.42333, 'val_acc': 0.875}\n",
      "Epoch 66/99\n",
      "------------------------------\n",
      "{'time': 31.05931, 'train_loss': 0.14798, 'train_acc': 0.94712, 'val_loss': 0.39057, 'val_acc': 0.8882}\n",
      "Epoch 67/99\n",
      "------------------------------\n",
      "{'time': 30.7145, 'train_loss': 0.14356, 'train_acc': 0.94914, 'val_loss': 0.42575, 'val_acc': 0.877}\n",
      "Epoch 68/99\n",
      "------------------------------\n",
      "{'time': 32.68147, 'train_loss': 0.14444, 'train_acc': 0.94744, 'val_loss': 0.40426, 'val_acc': 0.8818}\n",
      "Epoch 69/99\n",
      "------------------------------\n",
      "{'time': 30.29848, 'train_loss': 0.14352, 'train_acc': 0.94806, 'val_loss': 0.40383, 'val_acc': 0.8756}\n",
      "Epoch 70/99\n",
      "------------------------------\n",
      "{'time': 30.38651, 'train_loss': 0.13835, 'train_acc': 0.95032, 'val_loss': 0.43737, 'val_acc': 0.876}\n",
      "Epoch 71/99\n",
      "------------------------------\n",
      "{'time': 31.19241, 'train_loss': 0.13882, 'train_acc': 0.9497, 'val_loss': 0.39093, 'val_acc': 0.88}\n",
      "Epoch 72/99\n",
      "------------------------------\n",
      "{'time': 34.19821, 'train_loss': 0.14105, 'train_acc': 0.9497, 'val_loss': 0.37805, 'val_acc': 0.8858}\n",
      "Epoch 73/99\n",
      "------------------------------\n",
      "{'time': 30.68826, 'train_loss': 0.13921, 'train_acc': 0.95012, 'val_loss': 0.38866, 'val_acc': 0.8852}\n",
      "Epoch 74/99\n",
      "------------------------------\n",
      "{'time': 29.38032, 'train_loss': 0.1351, 'train_acc': 0.95142, 'val_loss': 0.40824, 'val_acc': 0.8808}\n",
      "Epoch 75/99\n",
      "------------------------------\n",
      "{'time': 29.91979, 'train_loss': 0.13275, 'train_acc': 0.95262, 'val_loss': 0.41105, 'val_acc': 0.881}\n",
      "Epoch 76/99\n",
      "------------------------------\n",
      "{'time': 29.44022, 'train_loss': 0.12468, 'train_acc': 0.9555, 'val_loss': 0.4353, 'val_acc': 0.881}\n",
      "Epoch 77/99\n",
      "------------------------------\n",
      "{'time': 29.39373, 'train_loss': 0.13274, 'train_acc': 0.9525, 'val_loss': 0.40897, 'val_acc': 0.8826}\n",
      "Epoch 78/99\n",
      "------------------------------\n",
      "{'time': 29.04033, 'train_loss': 0.12537, 'train_acc': 0.9552, 'val_loss': 0.40162, 'val_acc': 0.886}\n",
      "Epoch 79/99\n",
      "------------------------------\n",
      "{'time': 29.31096, 'train_loss': 0.09063, 'train_acc': 0.9688, 'val_loss': 0.35739, 'val_acc': 0.8976}\n",
      "Epoch 80/99\n",
      "------------------------------\n",
      "{'time': 29.38258, 'train_loss': 0.0761, 'train_acc': 0.97362, 'val_loss': 0.36626, 'val_acc': 0.8976}\n",
      "Epoch 81/99\n",
      "------------------------------\n",
      "{'time': 29.22865, 'train_loss': 0.07412, 'train_acc': 0.97474, 'val_loss': 0.3513, 'val_acc': 0.896}\n",
      "Epoch 82/99\n",
      "------------------------------\n",
      "{'time': 29.58308, 'train_loss': 0.07056, 'train_acc': 0.97616, 'val_loss': 0.35683, 'val_acc': 0.9016}\n",
      "Epoch 83/99\n",
      "------------------------------\n",
      "{'time': 35.04054, 'train_loss': 0.06969, 'train_acc': 0.97534, 'val_loss': 0.35513, 'val_acc': 0.8952}\n",
      "Epoch 84/99\n",
      "------------------------------\n",
      "{'time': 30.1165, 'train_loss': 0.06802, 'train_acc': 0.9769, 'val_loss': 0.36085, 'val_acc': 0.8964}\n",
      "Epoch 85/99\n",
      "------------------------------\n",
      "{'time': 30.7663, 'train_loss': 0.06452, 'train_acc': 0.97824, 'val_loss': 0.36413, 'val_acc': 0.8956}\n",
      "Epoch 86/99\n",
      "------------------------------\n",
      "{'time': 30.26882, 'train_loss': 0.06256, 'train_acc': 0.9783, 'val_loss': 0.36843, 'val_acc': 0.9006}\n",
      "Epoch 87/99\n",
      "------------------------------\n",
      "{'time': 29.90235, 'train_loss': 0.06245, 'train_acc': 0.97912, 'val_loss': 0.35958, 'val_acc': 0.896}\n",
      "Epoch 88/99\n",
      "------------------------------\n",
      "{'time': 29.92306, 'train_loss': 0.05937, 'train_acc': 0.98018, 'val_loss': 0.36073, 'val_acc': 0.9016}\n",
      "Epoch 89/99\n",
      "------------------------------\n",
      "{'time': 31.39569, 'train_loss': 0.06141, 'train_acc': 0.97946, 'val_loss': 0.39906, 'val_acc': 0.8924}\n",
      "Epoch 90/99\n",
      "------------------------------\n",
      "{'time': 30.07989, 'train_loss': 0.05982, 'train_acc': 0.97938, 'val_loss': 0.38058, 'val_acc': 0.8976}\n",
      "Epoch 91/99\n",
      "------------------------------\n",
      "{'time': 30.25805, 'train_loss': 0.05938, 'train_acc': 0.97984, 'val_loss': 0.38107, 'val_acc': 0.8974}\n",
      "Epoch 92/99\n",
      "------------------------------\n",
      "{'time': 32.77907, 'train_loss': 0.0576, 'train_acc': 0.98042, 'val_loss': 0.37413, 'val_acc': 0.8968}\n",
      "Epoch 93/99\n",
      "------------------------------\n",
      "{'time': 29.19663, 'train_loss': 0.05756, 'train_acc': 0.97986, 'val_loss': 0.37014, 'val_acc': 0.8984}\n",
      "Epoch 94/99\n",
      "------------------------------\n",
      "{'time': 29.43219, 'train_loss': 0.05471, 'train_acc': 0.98114, 'val_loss': 0.37669, 'val_acc': 0.9006}\n",
      "Epoch 95/99\n",
      "------------------------------\n",
      "{'time': 29.22357, 'train_loss': 0.05502, 'train_acc': 0.98082, 'val_loss': 0.36787, 'val_acc': 0.8968}\n",
      "Epoch 96/99\n",
      "------------------------------\n",
      "{'time': 29.13499, 'train_loss': 0.05396, 'train_acc': 0.98174, 'val_loss': 0.38033, 'val_acc': 0.894}\n",
      "Epoch 97/99\n",
      "------------------------------\n",
      "{'time': 29.28601, 'train_loss': 0.05538, 'train_acc': 0.98116, 'val_loss': 0.37803, 'val_acc': 0.8982}\n",
      "Epoch 98/99\n",
      "------------------------------\n",
      "{'time': 29.04727, 'train_loss': 0.05377, 'train_acc': 0.98224, 'val_loss': 0.36232, 'val_acc': 0.8992}\n",
      "Epoch 99/99\n",
      "------------------------------\n",
      "{'time': 29.13059, 'train_loss': 0.05322, 'train_acc': 0.98162, 'val_loss': 0.39986, 'val_acc': 0.8958}\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"Epoch {}/{}\".format(epoch, epochs - 1))\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    \n",
    "    epoch_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    epoch_acc = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    \n",
    "    running_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    running_corrects = {\"train\": 0, \"validation\": 0}\n",
    "    \n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train(True)\n",
    "        else:\n",
    "            model.train(False)\n",
    "        \n",
    "        for data in data_loaders[phase]:\n",
    "            inputs, labels = data \n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() # clear all gradients\n",
    "            \n",
    "            outputs = model(inputs) # batch_size x num_classes\n",
    "            _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()  # compute gradients\n",
    "                optimizer.step() # update weights/biases\n",
    "               \n",
    "            running_loss[phase] += loss.data.item() * inputs.size(0)\n",
    "            running_corrects[phase] += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        epoch_loss[phase] = running_loss[phase] / dataset_sizes[phase]\n",
    "        epoch_acc[phase] =  running_corrects[phase] / dataset_sizes[phase]\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "        'time': np.round(time.time()-start_time, 5),\n",
    "        'train_loss': np.round(epoch_loss[\"train\"], 5),\n",
    "        'train_acc': np.round(epoch_acc[\"train\"], 5),\n",
    "        'val_loss': np.round(epoch_loss[\"validation\"], 5),\n",
    "        'val_acc': np.round(epoch_acc[\"validation\"], 5),\n",
    "    })\n",
    "    \n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e21bd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 27321.16112, 'test_loss': 0.39032, 'test_acc': 0.8982}\n"
     ]
    }
   ],
   "source": [
    "### evaluating the model with test set\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # clear all gradients\n",
    "\n",
    "        outputs = model(inputs) # batch_size x num_classes\n",
    "        _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        running_loss += loss.data.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "    'time': np.round(time.time()-start_time, 5),\n",
    "    'test_loss': np.round(running_loss/ dataset_sizes['test'], 5),\n",
    "    'test_acc': np.round(running_corrects/ dataset_sizes['test'], 5),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b2bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
